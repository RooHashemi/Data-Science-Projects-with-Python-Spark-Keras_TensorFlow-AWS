{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description & Problem statement: \n",
    "I will use the Yelp Review Data Set from Kaggle. Each observation in this dataset is a review of a particular business by a particular user. The \"stars\" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review. The \"cool\" column is the number of \"cool\" votes this review received from other Yelp users. The \"useful\" and \"funny\" columns are similar to the \"cool\" column. Here, the goal is to model/clusterize the topics of Yelp reviews. \n",
    "\n",
    "# Workflow:\n",
    "- Load the dataset\n",
    "- Data cleaning (e.g. remove formats and punctuations)\n",
    "- Basic data exploration\n",
    "- Text vectorization, using \"Bag of Words\" technique\n",
    "- Use \"Latent Dirichlet Allocation\" for document clustering (i.e. topic modeling)\n",
    "- Determine, sort and print most important words/features for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# we insatll and import spacy package for some advanced tokenizaion techniques:\n",
    "import spacy\n",
    "\n",
    "# we also install and import mglearn package (using !pip install mglearn) for some interesting visualization of results:\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 3EA9-93A4\n",
      "\n",
      " Directory of C:\\Users\\rhash\\Documents\\Datasets\\NLP projects (sklearn & Spark)\n",
      "\n",
      "09/11/2018  02:13 PM    <DIR>          .\n",
      "09/11/2018  02:13 PM    <DIR>          ..\n",
      "09/11/2018  02:11 PM    <DIR>          .ipynb_checkpoints\n",
      "09/10/2018  11:29 AM    <DIR>          aclImdb\n",
      "09/10/2018  11:57 AM    <DIR>          cache\n",
      "08/02/2018  06:00 PM           100,912 Dataset_Challenge_Dataset_Agreement.pdf\n",
      "09/11/2018  12:54 AM           149,226 IMDb review (positive vs negative reviews, in sklearn).ipynb\n",
      "09/11/2018  10:02 AM             8,797 IMDb review (topic modeling, sklearn).ipynb\n",
      "04/18/2011  02:53 PM             5,868 readme\n",
      "09/11/2018  10:53 AM           198,102 sms filteration (ham vs spam, sklearn).ipynb\n",
      "09/11/2018  10:54 AM            27,708 sms filteration (topic modeling, sklearn)-Copy1.ipynb\n",
      "03/15/2011  10:36 PM           477,907 SMSSpamCollection\n",
      "09/11/2018  02:13 PM           222,900 Yelp review (1 vs 5 star, sklearn).ipynb\n",
      "09/11/2018  02:13 PM             5,790 Yelp review (document clustering, sklearn).ipynb\n",
      "02/07/2018  01:02 AM     3,791,120,545 yelp_review.csv\n",
      "09/11/2018  11:33 AM     1,602,777,975 yelp_review.csv.zip\n",
      "09/11/2018  11:14 AM     3,149,412,274 yelp-dataset.zip\n",
      "              12 File(s)  8,544,508,004 bytes\n",
      "               5 Dir(s)  390,860,689,408 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and prepare the text data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('yelp_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(max_features=500, \n",
    "                       stop_words=\"english\",\n",
    "                       ngram_range=(1, 1),\n",
    "                       max_df=0.3)\n",
    "\n",
    "X = vect.fit_transform(reviews['text'][0:100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# document clustering with Latent Dirichlet Allocation:  LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation \n",
    "lda = LatentDirichletAllocation(n_topics=5, \n",
    "                                learning_method=\"batch\",                                \n",
    "                                max_iter=24, \n",
    "                                random_state=42)\n",
    "\n",
    "# We build the model and transform the data in one step  \n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each topic (a row in the components_), sort the features (ascending) \n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1] \n",
    "\n",
    "# Get the feature names from the vectorizer \n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "time          ordered       service       like          like          \n",
      "just          restaurant    staff         chicken       vegas         \n",
      "said          service       friendly      just          room          \n",
      "service       pizza         recommend     ve            nice          \n",
      "did           came          best          really        bar           \n",
      "got           menu          love          burger        just          \n",
      "told          table         amazing       fries         really        \n",
      "didn          server        time          try           night         \n",
      "like          delicious     ve            delicious     pretty        \n",
      "don           dinner        definitely    don           people        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the 5 topics: \n",
    "mglearn.tools.print_topics(topics=range(5), feature_names=feature_names,   \n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
