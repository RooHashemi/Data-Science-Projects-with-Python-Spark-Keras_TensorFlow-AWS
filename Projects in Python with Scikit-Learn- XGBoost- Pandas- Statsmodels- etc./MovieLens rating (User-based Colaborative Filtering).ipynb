{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description & Problem statement: \n",
    "One of the most common datasets that is available on the internet for building a Recommender System is the MovieLens DataSet. This version of the dataset that I'm working with (100K) contains 100,000 ratings from 1000 users on 1700 movies. Released 4/1998. The data was collected by GroupLens researchers over various periods of time, depending on the size of the set. Users were selected at random for inclusion. All users selected had rated at least 20 movies. Each user is represented by an id, and no other information is provided. The original data are contained in three files, movies.dat, ratings.dat and users.dat. \n",
    "In this project, I use the User-based collaborative filtering to predict the rating of a user on a new item.\n",
    "\n",
    "\n",
    "# Theory of Collaborative Filtering (CF):\n",
    "There are 2 main types of memory-based collaborative filtering algorithms:\n",
    "\n",
    "1) User-User Collaborative Filtering: Here I find look alike users based on similarity and recommend movies which first user’s look-alike has chosen in past. This algorithm is very effective but takes a lot of time and resources. It requires to compute every user pair information which takes time. Therefore, for big base platforms, this algorithm is hard to implement without a very strong parallelizable system.\n",
    "\n",
    "2) Item-Item Collaborative Filtering: It is quite similar to previous algorithm, but instead of finding user's look-alike, I try finding movie's look-alike. Once we have movie's look-alike matrix, we can easily recommend alike movies to user who have rated any movie from the dataset. This algorithm is far less resource consuming than user-user collaborative filtering. Hence, for a new user, the algorithm takes far lesser time than user-user collaborate as I don’t need all similarity scores between users. And with fixed number of movies, movie-movie look alike matrix is fixed over time.\n",
    "\n",
    "Note: Here, I use User-based CF.\n",
    "\n",
    "# Workflow:\n",
    "- Load and merge the datasets\n",
    "- Creat functions to calculate the User-User similarity, using:\n",
    "     - Euclidian distance\n",
    "     - Pearson's correlation\n",
    "     - Corrected Pearson's correlation\n",
    "     \n",
    "- Object Oriented Programming to:\n",
    "     - compute the User-User similarity matrix for all Users, using one of similarity functions defined above\n",
    "     - predict the User rating on a new Item, using all User-User similarities \n",
    "\n",
    "- Define functions to calculate RMSE and evaluate the Recommender System\n",
    "- Evaluate the Recommender System for different similarity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from math import isnan\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='times')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10) \n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 3EA9-93A4\n",
      "\n",
      " Directory of C:\\Users\\rhash\\Documents\\Datasets\\Recommender systems\n",
      "\n",
      "09/15/2018  01:21 AM    <DIR>          .\n",
      "09/15/2018  01:21 AM    <DIR>          ..\n",
      "09/14/2018  08:05 PM    <DIR>          .ipynb_checkpoints\n",
      "09/15/2018  01:15 AM            14,802 itemBased_CF (Movie Lens Data).ipynb\n",
      "09/14/2018  09:42 AM    <DIR>          ml-100k\n",
      "09/15/2018  01:21 AM            15,906 userBased_CF (Movie Lens Data).ipynb\n",
      "               2 File(s)         30,708 bytes\n",
      "               4 Dir(s)  390,187,143,168 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La BD has 100000 ratings\n",
      "La BD has  943  users\n",
      "La BD has  1682  movies\n",
      "\n",
      "   user_id         title  movie_id  rating release_date sex  age\n",
      "0      196  Kolya (1996)       242       3  24-Jan-1997   M   49\n",
      "1      305  Kolya (1996)       242       5  24-Jan-1997   M   23\n",
      "2        6  Kolya (1996)       242       4  24-Jan-1997   M   42\n",
      "3      234  Kolya (1996)       242       4  24-Jan-1997   M   60\n",
      "4       63  Kolya (1996)       242       3  24-Jan-1997   M   31\n"
     ]
    }
   ],
   "source": [
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "# movies file contains columns indicating the movie's genres\n",
    "# let's load only the first three columns of movie file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='cp1250')\n",
    "\n",
    "# merge the DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.user_id.nunique(),\" users\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\\n\")\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of common movies 132 \n",
      "\n",
      "                                    title  rating\n",
      "2                            Kolya (1996)       4\n",
      "885                Raising Arizona (1987)       5\n",
      "1255  Truth About Cats & Dogs, The (1996)       2\n",
      "1854          English Patient, The (1996)       2\n",
      "2636                          Babe (1995)       4 \n",
      "\n",
      "                                    title  rating\n",
      "13                           Kolya (1996)       5\n",
      "939                Raising Arizona (1987)       5\n",
      "1303  Truth About Cats & Dogs, The (1996)       3\n",
      "1906          English Patient, The (1996)       5\n",
      "2676                          Babe (1995)       5\n"
     ]
    }
   ],
   "source": [
    "# dataframe with the data from user 1\n",
    "data_user_1 = data[data.user_id==6]\n",
    "\n",
    "# dataframe with the data from user 2\n",
    "data_user_2 = data[data.user_id==18]\n",
    "\n",
    "# We first compute the set of common movies\n",
    "common_movies = set(data_user_1.movie_id) & set(data_user_2.movie_id)\n",
    "print(\"\\nNumber of common movies\", len(common_movies),'\\n')\n",
    "\n",
    "# creat the subdataframe with only with the common movies\n",
    "mask = (data_user_1.movie_id.isin(common_movies))\n",
    "data_user_1 = data_user_1[mask]\n",
    "print(data_user_1[['title','rating']].head(), '\\n')\n",
    "\n",
    "mask = (data_user_2.movie_id.isin(common_movies))\n",
    "data_user_2 = data_user_2[mask]\n",
    "print(data_user_2[['title','rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the similarity functions:\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Returns a distance-based similarity score for user 1 and user 2:\n",
    "def SimEuclid(DataFrame, User1, User2, min_common_items=1):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id'] ==User1 ]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id'] ==User2 ]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1, movies_user2, on='movie_id')  \n",
    "    \n",
    "    if len(rep)==0:\n",
    "        return 0\n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0\n",
    "    #return distEuclid(rep['rating_x'],rep['rating_y']) \n",
    "    return 1.0/(1.0+euclidean(rep['rating_x'],rep['rating_y'])) \n",
    "\n",
    "# Returns a pearsonCorrealation-based similarity score for user 1 and user 2:\n",
    "def SimPearson(DataFrame, User1, User2, min_common_items=1):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id'] ==User1 ]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id'] ==User2 ]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1, movies_user2, on='movie_id')\n",
    "    \n",
    "    if len(rep)==0:\n",
    "        return 0    \n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0    \n",
    "    res=pearsonr(rep['rating_x'],rep['rating_y'])[0]\n",
    "    if(isnan(res)):\n",
    "        return 0\n",
    "    return res\n",
    "\n",
    "# Returns a corrected pearsonCorrealation-based similarity score for user 1 and user 2:\n",
    "def SimPearson_Corrected(DataFrame, User1, User2, min_common_items=1, pref_common_items=20):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id']==User1]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id']==User2]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1, movies_user2, on='movie_id')\n",
    "    if len(rep)==0:\n",
    "        return 0    \n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0\n",
    "    \n",
    "    res=pearsonr(rep['rating_x'],rep['rating_y'])[0] * min(pref_common_items,len(rep))/pref_common_items\n",
    "    if(isnan(res)):\n",
    "        return 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Object Oriented Programming, to:\n",
    "    - compute the User-User similarity matrix for all Users, using one of similarity functions defined above,\n",
    "    - predict the User rating on a new Item, using all User-User similarities. \"\"\"\n",
    "\n",
    "class userBased_CF:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, DataFrame, similarity=SimPearson, min_common_items=10, max_sim_users=10):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity #Gets recommendations for a person by using a weighted average\n",
    "        self.df=DataFrame\n",
    "        self.sim = pd.DataFrame(np.sum([0]), columns=data_train.user_id.unique(), index=data_train.user_id.unique())\n",
    "        self.min_common_items=min_common_items\n",
    "        self.max_sim_users=max_sim_users\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\" Prepare data structures for estimation. compute User-User Similarity Matrix for all users \"\"\"\n",
    "        allUsers=set(self.df['user_id'])\n",
    "        self.sim = {}\n",
    "        for person1 in allUsers:\n",
    "            self.sim.setdefault(person1, {})\n",
    "            a=data_train[data_train['user_id']==person1][['movie_id']]\n",
    "            data_reduced=pd.merge(data_train, a, on='movie_id')\n",
    "            \n",
    "            for person2 in allUsers:\n",
    "                # don't compare the user with itself\n",
    "                if person1==person2: \n",
    "                    continue\n",
    "                self.sim.setdefault(person2, {})\n",
    "                \n",
    "                if (person1 in self.sim[person2]):\n",
    "                    continue  # since correlation matrix is a symmetric matrix\n",
    "                \n",
    "                sim=self.sim_method(data_reduced, person1, person2, self.min_common_items)\n",
    "                \n",
    "                ### print person1, person2, sim\n",
    "                \n",
    "                if(sim<0):\n",
    "                    self.sim[person1][person2]=0\n",
    "                    self.sim[person2][person1]=0\n",
    "                else:\n",
    "                    self.sim[person1][person2]=sim\n",
    "                    self.sim[person2][person1]=sim\n",
    "                    \n",
    "        self.mean_ratings=mean_rating \\\n",
    "                         =data_train[['user_id','movie_id','rating']].groupby('user_id')['rating'].mean()\n",
    "                \n",
    "                \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \n",
    "        totals={}\n",
    "        movie_users=self.df[self.df['movie_id'] ==movie_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        allUsers=set(movie_users['user_id'])\n",
    "        listOrdered=sorted([(self.sim[user_id][other],other) for other in allUsers if user_id!=other],reverse=True)\n",
    "        \n",
    "        for item in range(min(len(listOrdered),self.max_sim_users)):\n",
    "            other=listOrdered[item][1]\n",
    "            rating_num += self.sim[user_id][other] * (float(movie_users[movie_users['user_id']==other]['rating']-self.mean_ratings[other]))\n",
    "            rating_den += self.sim[user_id][other]\n",
    "        if rating_den==0: \n",
    "            if self.df.rating[self.df['movie_id']==movie_id].mean()>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return self.df.rating[self.df['movie_id']==movie_id].mean()\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "        return self.mean_ratings[user_id]+rating_num/rating_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data_set has 74646 ratings\n",
      "Test data set has 25354 ratings\n",
      "It has  1682  movies\n"
     ]
    }
   ],
   "source": [
    "test_size=0.25\n",
    "\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                  size=np.int64(np.ceil(df.index.size * test_size)),\n",
    "                                  replace=False)\n",
    "    df.ix[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "data['for_testing'] = False\n",
    "grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "data_train = data[grouped.for_testing == False]\n",
    "data_test = data[grouped.for_testing == True]\n",
    "\n",
    "#print(data_train.shape)\n",
    "#print(data_test.shape)\n",
    "#print(data_train.index & data_test.index, '\\n')\n",
    "\n",
    "print(\"Training data_set has \"+ str(data_train.shape[0]) +\" ratings\")\n",
    "print(\"Test data set has \"+ str(data_test.shape[0]) +\" ratings\")\n",
    "print(\"It has \", data.movie_id.nunique(), \" movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate RMSE\n",
    "def  compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to evaluate Recommender System\n",
    "def  evaluate (estimate_f, data_train, data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([estimate_f(u,i) if u in data_train.user_id else 3  for (u,i) in ids_to_estimate ])\n",
    "    \n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "record=userBased_CF(data_train, similarity=SimPearson, min_common_items=3, max_sim_users=10)\n",
    "record.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Collaborative Recomender (using User-User Correlation Similarity):  1.039392771277547\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for Collaborative Recomender (using User-User Correlation Similarity):  %s' % \n",
    "                                                                    evaluate(record.estimate, data_train, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_new=userBased_CF(data_train, similarity=SimPearson_Corrected, min_common_items=3, max_sim_users=10)\n",
    "record_new.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Collaborative Recomender (using Corrected User-User Correlation Similarity):  1.027682960355351\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for Collaborative Recomender (using Corrected User-User Correlation Similarity):  %s' % \n",
    "                                                                    evaluate(record_new.estimate, data_train, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
